# 什么是并发编程
在了解并发编程带来的挑战之前，我们首先需要了解什么是并发编程。  
  
所谓并发编程是指在一台处理器上“同时”处理多个任务。并发是在同一实体上的多个事件。多个事件在同一时间间隔发生。并发编程的目标是充分的利用处理器的每一个核，以达到最高的处理性能。  
  
而在Java中常以多线程来处理并发。并发编程的目的是为了让程序运行得更快，但是，并不是启动更多的线程就能让程序最大限度地开发执行。在进行并发编程时，如果希望让多线程执行任务让程序运行的更快，会面临非常多的挑战，比如上下文切换问题、死锁的问题，以及受限于硬件和软件的资源限制问题。
# 并发编程的挑战
## 1.1 &nbsp; 上下文切换
即使是单核处理器也支持多线程执行代码，CPU通过给每个线程分配CPU时间片来实现这个机制。时间片是CPU分配给各个线程的时间，因为时间片非常短，所以CPU通过不停的切换线程执行，让我们感觉多个线程是同时执行的，时间片一般是几十毫秒（ms）。

CPU通过[时间片](https://baike.baidu.com/item/%E6%97%B6%E9%97%B4%E7%89%87%E8%BD%AE%E8%BD%AC%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/7170554)分配算法来循环执行任务，当前任务执行一个时间片后会切换到下个任务，但是在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这个任务的状态。所以任务的保存到再加载的过程就是一次上下文切换。

就像我们同时在读两本书，比如当我们在读一本英文的技术书时，发现某个单词不认识，于是便打开中英文字典，但是在放下英文技术书之前，大脑必需首先记住这本书读到了多少页的第多少行，等查完单词之后，能够继续读这本书，这样的切换是会影响读书效率的，同样上下文切换也会影响到多线程的执行速度。  
  
  
##   1.1.1 &nbsp; 多线程一定快吗  
下面的代码演示串行和并发执行累加操作的时间，请思考下面的代码并发执行一定比串行执行快些吗？

```
public class ConcurrencyTest {
	
	private static final long count = 1000001;
	
	private static void currency() throws InterruptedException{
		long start = System.currentTimeMillis();
		Thread thread = new Thread(new Runnable() {
			
			@Override
			public void run() {
				// TODO Auto-generated method stub
				int a = 0;
				for(long i = 0; i < count; i++){
					a += 5;
				}
			}
		});
		thread.start();
		int b = 0;
		for (long i = 0; i < count ;i++){
			b--;
		}
		long time = System.currentTimeMillis() - start;
		thread.join();
		System.out.println("currency:" + time + "ms,b=" + b);
	}
	
	public static void serial(){
		long start = System.currentTimeMillis();
		int a = 0;
		for(long i = 0; i < count; i++){
			a += 5;
		}
		int b = 0;
		for (long i = 0; i < count ;i++){
			b--;
		}
		long time = System.currentTimeMillis() - start;
		System.out.println("serial:" + time + "ms,b=" + b + ",a=" + a);
	}
	
	public static void main(String[] args) throws InterruptedException {
		currency();
		serial();
	}
	
}

```
表1-1 测试结果
循环次数 | 串行执行 | 并行执行消耗 | 并发比串行快多少
---|---|---|---
1亿 | 130 | 77 | 约1倍
1千万 | 18 | 9 | 约1倍
1百万 | 5 | 5 | 差不多
10万 | 4 | 3 | 慢
1万 | 0 | 1 | 慢
## 1.1.2 &nbsp;如何减少上下文切换
减少上下文切换的方法有无锁并发编程、CAS算法、单线程编程和使用协程。

- 无锁并发编程。多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据用ID进行Hash算法后分段，不同的线程处理不同段的数据。
- CAS算法。Java的Atomic包使用CAS算法来更新数据，而不需要加锁。
- 使用最少线程。避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样会造成大量线程都处于等待状态。
- [协程](https://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/0013868328689835ecd883d910145dfa8227b539725e5ed000)：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。（一种用户状态的轻量级锁，又称微线程，协程的调度完全由用户控制。它的转换由程序控制）
# 1.2 死锁
锁是个非常有用的工具，运用场景非常多，因为其使用起来非常简单，而且易于理解。但同时它也会带来一些困扰，那就是可能会引起死锁，一旦产生死锁，会造成系统功能不可用。让我们先来看一段代码，这段代码会引起死锁，线程t1和t2互相等待对方释放锁。  

```
/**
 * 死锁例子
 *
 * @author tengfei.fangtf
 * @version $Id: DeadLockDemo.java, v 0.1 2015-7-18 下午10:08:28 tengfei.fangtf Exp $
 */
public class DeadLockDemo {

    /** A锁 */
    private static String A = "A";
    /** B锁 */
    private static String B = "B";

    public static void main(String[] args) {
        new DeadLockDemo().deadLock();
    }

    private void deadLock() {
        Thread t1 = new Thread(new Runnable() {
            @Override
            public void run() {
                synchronized (A) {
                    try {
                        Thread.sleep(2000);
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                    synchronized (B) {
                        System.out.println("1");
                    }
                }
            }
        });

        Thread t2 = new Thread(new Runnable() {
            @Override
            public void run() {
                synchronized (B) {
                    synchronized (A) {
                        System.out.println("2");
                    }
                }
            }
        });
        t1.start();
        t2.start();
    }

}
```
这段代码只是演示死锁的场景，在现实中你可能很难会写出这样的代码。但是一些更为复杂的场景中你可能会遇到这样的问题，比如t1拿到锁之后，因为一些异常情况没有释放锁，比如死循环。又或者是t1拿到一个数据库锁，释放锁的时候抛了异常，没释放掉。    

现在我们介绍下如何避免死锁的几个常见方法。  
- 避免一个线程同时获取多个锁。
- 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。
- 尝试使用定时锁，使用tryLock(timeout)来替代使用内部锁机制。
- 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败。
# 1.3 资源限制的挑战
（1）什么是资源限制？  

资源限制是指在进行并发编程时，程序的执行速度受限于计算机硬件资源或软件资源的限制。比如服务器的带宽只有2M，某个资源的下载速度是1M每秒，系统启动十个线程下载资源，下载速度不会变成10M每秒，所以在进行并发编程时，要考虑到这些资源的限制。硬件资源限制有带宽的上传下载速度，硬盘读写速度和CPU的处理速度。软件资源限制有数据库的连接数和Sorket连接数等。

（2）资源限制引发的问题  

并发编程将代码执行速度加速的原则是将代码中串行执行的部分变成并发执行，但是如果某段串行的代码并发执行，但是因为受限于资源的限制，仍然在串行执行，这时候程序不仅不会执行加快，反而会更慢，因为增加了上下文切换和资源调度的时间。例如，之前看到一段程序使用多线程在办公网并发的下载和处理数据时，导致CPU利用率100％，任务几个小时都不能运行完成，后来修改成单线程，一个小时就执行完成了。

 

（3）如何解决资源限制的问题？  

对于硬件资源限制，可以考虑使用集群并行执行程序，既然单机的资源有限制，那么就让程序在多机上运行，比如使用ODPS，hadoop或者自己搭建服务器集群，不同的机器处理不同的数据，比如将数据ID％机器数，得到一个机器编号，然后由对应编号的机器处理这笔数据。

对于软件资源限制，可以考虑使用资源池将资源复用，比如使用连接池将数据库和Sorket连接复用，或者调用对方webservice接口获取数据时，只建立一个连接。

 

（4）在资源限制情况下进行并发编程  

那么如何在资源限制的情况下，让程序执行的更快呢？根据不同的资源限制调整程序的并发度，比如下载文件程序依赖于两个资源，带宽和硬盘读写速度。有数据库操作时，要数据库连接数，如果SQL语句执行非常快，而线程的数量比数据库连接数大很多，则某些线程会被阻塞住，等待数据库连接。